{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39ba083",
   "metadata": {},
   "source": [
    "# Other cuda features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff4cf9",
   "metadata": {},
   "source": [
    "## Atomic operations\n",
    "\n",
    "The [official CUDA documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions) refers to atomic operations as:\n",
    "\n",
    "> \"The operation is atomic in the sense that it is guaranteed to be performed without interference from other threads. In other words, no other thread can access this address until the operation is complete\"\n",
    "\n",
    "Atomic operations function as _locks_ and avoid race conditions. This is especially useful for CUDA programms which primarily work in parallel.\n",
    "\n",
    "Supported operations in Numba are: `add, compare_and_swap, max, min, nanmax, nanmin, sub`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2df869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in Array using atomic operations:\n",
      "0.9998963561775785\n",
      "Maximum value in Array using simple python:\n",
      "0.9998963561775785\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "@cuda.jit\n",
    "def find_max_value(result, input):\n",
    "    \"\"\"\n",
    "        Find the maximum value of the input array\n",
    "    \"\"\"\n",
    "    \n",
    "    i = cuda.grid(1)\n",
    "        \n",
    "    # Is i the new minimum value?\n",
    "    cuda.atomic.max(result, 0, input[i])\n",
    "    \n",
    "# Array of random values\n",
    "inArray = np.random.rand(16384)\n",
    "result = np.zeros(1, dtype=np.float64)\n",
    "\n",
    "find_max_value[256, 64](result, inArray)\n",
    "\n",
    "print(f\"Maximum value in Array using atomic operations:\\n{result[0]}\")\n",
    "print(f\"Maximum value in Array using simple python:\\n{max(inArray)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916bd6b9",
   "metadata": {},
   "source": [
    "## Select device to use\n",
    "\n",
    "As show in the intro, Numba provides ways to select the GPU. Nevertheless, most of the times this should not be needed , as Numba automatically chooses the fastest devcice available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a68a1cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avvailable GPUs: <Managed Device 0>\n",
      "GPU currently in use: <Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "cuda.select_device(0) # Default = fastest\n",
    "\n",
    "# cuda.select_device(1) => Having more than one GPU available\n",
    "\n",
    "print(f\"Avvailable GPUs: {cuda.gpus}\")\n",
    "print(f\"GPU currently in use: {cuda.gpus.current}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
