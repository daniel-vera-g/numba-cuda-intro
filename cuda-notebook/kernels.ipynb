{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e0e263-7097-4646-8cc8-e5ee1c530f0b",
   "metadata": {},
   "source": [
    "# Kernels\n",
    "\n",
    "> GPU function called form the CPU\n",
    "\n",
    "- Pass and get data through arrays\n",
    "- Before calling Kernel function, declare thread hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e08fc0e-fd64-4570-a844-1fc6b8f90cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "# Our jit cuda enabled function \n",
    "@cuda.jit\n",
    "def test_kernel(an_array):\n",
    "    \"\"\"\n",
    "    TODO Add the code to be executed by CUDA here\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5efdad2-7b84-463d-9c74-3d420147f05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Declare kernel:\n",
    "\n",
    "# 1. Data array to work with\n",
    "# Docs: \"Return a new array of given shape and type, filled with ones.\"\n",
    "dataArr = np.ones(256)\n",
    "\n",
    "# 2. Define Thread values\n",
    "\n",
    "# Block size depending on size data array, shared memory, supported hardware, ...\n",
    "threads_in_block = 32\n",
    "blocks_in_grid = (dataArr.size + (threads_in_block - 1))\n",
    "\n",
    "# 3. \"Call\" Kernel\n",
    "test_kernel[blocks_in_grid, threads_in_block](dataArr)\n",
    "\n",
    "print(dataArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea35844-4268-48cc-991e-484a2f63e44b",
   "metadata": {},
   "source": [
    "## Positon of thread in grid & block\n",
    "\n",
    "> Get the position of thread by getting the information in the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95382ee-6350-4f01-99f8-a36529a7d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def position_kernel(an_array):\n",
    "    # Let's get the thread and corresponding block\n",
    "    tt = cuda.threadIdx.x # Aka. X-Dimension\n",
    "    tb = cuda.blockIdx.x # Aka. Y-Dimension\n",
    "    \n",
    "    # \"Size\" aka. width of Block: Number threads in Block\n",
    "    bs = cuda.blockDim.x\n",
    "    \n",
    "    position = tt + tb * bs\n",
    "\n",
    "    if position < an_array.size:\n",
    "        an_array[position] *= 2 # Just double size as example\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b94874c-2bb6-49db-a366-5a7a9a247bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Same as above:\n",
    "dataArr = np.ones(256)\n",
    "threads_in_block = 32\n",
    "blocks_in_grid = (dataArr.size + (threads_in_block - 1))\n",
    "\n",
    "position_kernel[blocks_in_grid, threads_in_block](dataArr)\n",
    "\n",
    "print(dataArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdc74e-bfa3-4656-b02f-e835c6f786dd",
   "metadata": {},
   "source": [
    "## Automating position search\n",
    "\n",
    "> Automate search for position using `numba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d2026b-0bad-407f-91b7-b49a60858924",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def automated_kernel(an_array):\n",
    "    # Docs: \"Return the absolute position of the current thread in the entire grid of blocks.\"\n",
    "    # `ndim` => Number dimensions\n",
    "    position = cuda.grid(1)\n",
    "        \n",
    "    # Same as above\n",
    "    if position < an_array.size:\n",
    "        an_array[position] *= 2 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c741723-cc44-47c1-afa6-fe9d4a3e0486",
   "metadata": {},
   "source": [
    "Add host to call Kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16574445-b1bd-4008-81bf-95fb66c0334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Same as above:\n",
    "dataArr = np.ones(256)\n",
    "threads_in_block = 32\n",
    "blocks_in_grid = (dataArr.size + (threads_in_block - 1))\n",
    "\n",
    "automated_kernel[blocks_in_grid, threads_in_block](dataArr)\n",
    "\n",
    "print(dataArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0fb8f",
   "metadata": {},
   "source": [
    "## Choosing the right block size\n",
    "\n",
    "The block size is a value representing the number of threads per block. To choose the right value, one should have the Hardware and Software considerations in mind.\n",
    "\n",
    "On the Hardware side, it has an impact on how much execution units are available. On the software side, it sets the number of threads a block has.\n",
    "\n",
    "The official [CUDA documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#thread-hierarchy) recommends a block size of 256 threads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
